{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61944,"databundleVersionId":6757506,"sourceType":"competition"}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\n\n# Load labels\ndf = pd.read_csv('/kaggle/input/iitgai-ovha-23/train_labels.csv')  \n\n# Assuming images are in the '/kaggle/input/iitgai-ovha-23/images/' folder\nimage_paths = df['image_name'].apply(lambda x: f'/kaggle/input/iitgai-ovha-23/images/{x}')\n\n# Function to load and preprocess images\ndef load_and_preprocess_image(image_path):\n    img = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n    img = keras.preprocessing.image.img_to_array(img)\n    img = keras.applications.resnet50.preprocess_input(img)\n    return img\n\nimages = np.array([load_and_preprocess_image(path) for path in image_paths])\n\n# Function to parse points from the 'points' column\ndef parse_points(points_str):\n    try:\n        # If points are already in list format as strings, eval() will convert them to a list\n        if isinstance(points_str, str):\n            return eval(points_str)\n        else:\n            return points_str\n    except Exception as e:\n        print(f\"Error parsing points: {e}, points_str: {points_str}\")\n        return None\n\n# Apply the parse_points function and remove problematic points\nlabels = df['points'].apply(parse_points)\nlabels = labels.dropna()\n\n# Convert labels to numpy array\nlabels = np.array(labels.tolist())\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n\n# Load pre-trained ResNet model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers\nmodel = keras.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(8)  # 8 output values for the coordinates\n])\n\n# Train the model for 200 epochs\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32)\n\n# Save the model\nmodel.save('/kaggle/working/icu_machine_detection_model.h5') \n\n# Print the final cost function (loss) of train and validation set\ntrain_loss = history.history['loss'][-1]\nval_loss = history.history['val_loss'][-1]\nprint(f'Final Training Loss: {train_loss:.4f}')\nprint(f'Final Validation Loss: {val_loss:.4f}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow import keras\n\n# Load the pre-trained model\nmodel = keras.models.load_model('/kaggle/working/icu_machine_detection_model.h5')  # Adjust the path if needed\n\n# Load the sample submission file\nsample_submission = pd.read_csv('/kaggle/input/iitgai-ovha-23/sample_submission.csv')\n\n# Assuming test images are in the '/kaggle/input/iitgai-ovha-23/test_images/' folder\ntest_image_paths = sample_submission['image_name'].apply(lambda x: f'/kaggle/input/iitgai-ovha-23/test_images/{x}')\n\n# Function to load and preprocess test images\ndef load_and_preprocess_test_image(image_path):\n    img = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n    img = keras.preprocessing.image.img_to_array(img)\n    img = keras.applications.resnet50.preprocess_input(img)\n    return img\n\ntest_images = np.array([load_and_preprocess_test_image(path) for path in test_image_paths])\n\n# Predict coordinates for test images\npredicted_coordinates = model.predict(test_images)\n\n# Create a DataFrame with image names and predicted coordinates\nsubmission_df = pd.DataFrame({\n    'image_name': sample_submission['image_name'],\n    'points': [f'[{coord[0]},{coord[1]},{coord[2]},{coord[3]}' for coord in predicted_coordinates]\n})\n\n# Save the submission file\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False) \n\n# Optionally, you can also print the first few rows of the submission DataFrame\nprint(submission_df.head())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Load labels\ndf = pd.read_csv('/kaggle/input/iitgai-ovha-23/train_labels.csv')  \n\n# Assuming images are in the '/kaggle/input/iitgai-ovha-23/images/' folder\nimage_paths = df['image_name'].apply(lambda x: f'/kaggle/input/iitgai-ovha-23/images/{x}')\n\n# Function to load and preprocess images\ndef load_and_preprocess_image(image_path):\n    img = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n    img = keras.preprocessing.image.img_to_array(img)\n    img = keras.applications.resnet50.preprocess_input(img)\n    return img\n\nimages = np.array([load_and_preprocess_image(path) for path in image_paths])\n\n# Function to parse points from the 'points' column\ndef parse_points(points_str):\n    try:\n        # If points are already in list format as strings, eval() will convert them to a list\n        if isinstance(points_str, str):\n            return eval(points_str)\n        else:\n            return points_str\n    except Exception as e:\n        print(f\"Error parsing points: {e}, points_str: {points_str}\")\n        return None\n\n# Apply the parse_points function and remove problematic points\nlabels = df['points'].apply(parse_points)\nlabels = labels.dropna()\n\n# Convert labels to numpy array\nlabels = np.array(labels.tolist())\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n\n# Apply data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Initialize an empty list to store augmented images and labels\naugmented_images = []\naugmented_labels = []\n\n# Apply data augmentation to each image and its corresponding label\nfor image, label in zip(X_train, y_train):\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    augmented_images.extend(datagen.flow(image).next())\n    augmented_labels.extend([label] * len(datagen.flow(image).next()))\n\n# Convert the lists of augmented images and labels back to numpy arrays\naugmented_images = np.array(augmented_images)\naugmented_labels = np.array(augmented_labels)\n\n# Combine original and augmented data\nX_combined = np.vstack((X_train, augmented_images))\ny_combined = np.vstack((y_train, augmented_labels))  # Assuming labels are 2D\n\n# Load pre-trained ResNet model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers\nmodel = keras.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(8)  # 8 output values for the coordinates\n])\n\n# Train the model for 200 epochs\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')\nhistory = model.fit(X_combined, y_combined, validation_data=(X_val, y_val), epochs=200, batch_size=32)\n\n# Save the model\nmodel.save('/kaggle/working/icu_machine_detection_model.h5') \n\n# Print the final cost function (loss) of train and validation set\ntrain_loss = history.history['loss'][-1]\nval_loss = history.history['val_loss'][-1]\nprint(f'Final Training Loss: {train_loss:.4f}')\nprint(f'Final Validation Loss: {val_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T17:02:35.732373Z","iopub.execute_input":"2023-10-15T17:02:35.732703Z","iopub.status.idle":"2023-10-15T17:58:42.455282Z","shell.execute_reply.started":"2023-10-15T17:02:35.732675Z","shell.execute_reply":"2023-10-15T17:58:42.454211Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/200\n90/90 [==============================] - 57s 202ms/step - loss: 288880.6562 - val_loss: 89484.2422\nEpoch 2/200\n90/90 [==============================] - 16s 180ms/step - loss: 261366.2656 - val_loss: 195906.2500\nEpoch 3/200\n90/90 [==============================] - 17s 187ms/step - loss: 240578.2188 - val_loss: 209384.0938\nEpoch 4/200\n90/90 [==============================] - 16s 180ms/step - loss: 221286.2031 - val_loss: 207784.9844\nEpoch 5/200\n90/90 [==============================] - 16s 180ms/step - loss: 203694.4062 - val_loss: 197483.5625\nEpoch 6/200\n90/90 [==============================] - 16s 179ms/step - loss: 186282.0312 - val_loss: 160822.8438\nEpoch 7/200\n90/90 [==============================] - 16s 180ms/step - loss: 170749.6406 - val_loss: 150858.6719\nEpoch 8/200\n90/90 [==============================] - 16s 179ms/step - loss: 154913.6250 - val_loss: 147905.2812\nEpoch 9/200\n90/90 [==============================] - 16s 180ms/step - loss: 140346.2656 - val_loss: 151261.1406\nEpoch 10/200\n90/90 [==============================] - 16s 179ms/step - loss: 126981.3672 - val_loss: 159363.8906\nEpoch 11/200\n90/90 [==============================] - 17s 187ms/step - loss: 114447.7031 - val_loss: 108442.8438\nEpoch 12/200\n90/90 [==============================] - 16s 180ms/step - loss: 101152.9219 - val_loss: 95480.2656\nEpoch 13/200\n90/90 [==============================] - 16s 180ms/step - loss: 90442.1641 - val_loss: 94474.9922\nEpoch 14/200\n90/90 [==============================] - 16s 179ms/step - loss: 79951.2812 - val_loss: 76146.1406\nEpoch 15/200\n90/90 [==============================] - 16s 181ms/step - loss: 70485.0703 - val_loss: 62126.3789\nEpoch 16/200\n90/90 [==============================] - 16s 179ms/step - loss: 61161.2227 - val_loss: 60156.2852\nEpoch 17/200\n90/90 [==============================] - 16s 180ms/step - loss: 52624.6211 - val_loss: 65770.7578\nEpoch 18/200\n90/90 [==============================] - 16s 180ms/step - loss: 45338.7656 - val_loss: 40153.8281\nEpoch 19/200\n90/90 [==============================] - 16s 180ms/step - loss: 39028.6602 - val_loss: 49250.8672\nEpoch 20/200\n90/90 [==============================] - 16s 179ms/step - loss: 32837.0547 - val_loss: 38771.9609\nEpoch 21/200\n90/90 [==============================] - 16s 180ms/step - loss: 27206.5469 - val_loss: 22338.6348\nEpoch 22/200\n90/90 [==============================] - 16s 180ms/step - loss: 22672.6367 - val_loss: 19570.9727\nEpoch 23/200\n90/90 [==============================] - 16s 180ms/step - loss: 18934.8125 - val_loss: 16258.7861\nEpoch 24/200\n90/90 [==============================] - 17s 186ms/step - loss: 15909.0830 - val_loss: 15154.6191\nEpoch 25/200\n90/90 [==============================] - 16s 180ms/step - loss: 13409.7695 - val_loss: 14685.2070\nEpoch 26/200\n90/90 [==============================] - 17s 186ms/step - loss: 11385.5537 - val_loss: 8509.1836\nEpoch 27/200\n90/90 [==============================] - 16s 180ms/step - loss: 9708.2227 - val_loss: 6979.5054\nEpoch 28/200\n90/90 [==============================] - 16s 180ms/step - loss: 8411.1758 - val_loss: 7078.9536\nEpoch 29/200\n90/90 [==============================] - 17s 186ms/step - loss: 7285.7290 - val_loss: 5838.8599\nEpoch 30/200\n90/90 [==============================] - 17s 187ms/step - loss: 6231.2856 - val_loss: 6015.8213\nEpoch 31/200\n90/90 [==============================] - 16s 180ms/step - loss: 5317.0737 - val_loss: 4303.1016\nEpoch 32/200\n90/90 [==============================] - 16s 180ms/step - loss: 4438.1787 - val_loss: 7630.3208\nEpoch 33/200\n90/90 [==============================] - 16s 180ms/step - loss: 3651.7607 - val_loss: 5011.7227\nEpoch 34/200\n90/90 [==============================] - 16s 181ms/step - loss: 2955.7500 - val_loss: 3189.3931\nEpoch 35/200\n90/90 [==============================] - 16s 179ms/step - loss: 2434.4998 - val_loss: 3210.6357\nEpoch 36/200\n90/90 [==============================] - 16s 180ms/step - loss: 1929.5392 - val_loss: 2262.1204\nEpoch 37/200\n90/90 [==============================] - 16s 180ms/step - loss: 1572.8981 - val_loss: 1909.2417\nEpoch 38/200\n90/90 [==============================] - 17s 187ms/step - loss: 1336.5374 - val_loss: 1268.0107\nEpoch 39/200\n90/90 [==============================] - 16s 179ms/step - loss: 1135.7225 - val_loss: 1133.7314\nEpoch 40/200\n90/90 [==============================] - 16s 180ms/step - loss: 972.9262 - val_loss: 963.5787\nEpoch 41/200\n90/90 [==============================] - 16s 180ms/step - loss: 852.9731 - val_loss: 790.1108\nEpoch 42/200\n90/90 [==============================] - 16s 181ms/step - loss: 782.3129 - val_loss: 713.8075\nEpoch 43/200\n90/90 [==============================] - 16s 179ms/step - loss: 730.5938 - val_loss: 1528.0374\nEpoch 44/200\n90/90 [==============================] - 16s 180ms/step - loss: 680.2637 - val_loss: 807.0683\nEpoch 45/200\n90/90 [==============================] - 16s 180ms/step - loss: 680.3401 - val_loss: 689.7410\nEpoch 46/200\n90/90 [==============================] - 17s 187ms/step - loss: 635.6039 - val_loss: 721.0205\nEpoch 47/200\n90/90 [==============================] - 16s 179ms/step - loss: 596.7029 - val_loss: 886.7494\nEpoch 48/200\n90/90 [==============================] - 16s 180ms/step - loss: 611.9308 - val_loss: 1814.1016\nEpoch 49/200\n90/90 [==============================] - 16s 179ms/step - loss: 618.9792 - val_loss: 611.3782\nEpoch 50/200\n90/90 [==============================] - 16s 181ms/step - loss: 628.2106 - val_loss: 690.8341\nEpoch 51/200\n90/90 [==============================] - 17s 187ms/step - loss: 547.3226 - val_loss: 1299.7092\nEpoch 52/200\n90/90 [==============================] - 17s 187ms/step - loss: 562.3591 - val_loss: 1534.7434\nEpoch 53/200\n90/90 [==============================] - 17s 187ms/step - loss: 535.0103 - val_loss: 814.7021\nEpoch 54/200\n90/90 [==============================] - 16s 179ms/step - loss: 552.0410 - val_loss: 529.5567\nEpoch 55/200\n90/90 [==============================] - 16s 181ms/step - loss: 548.9884 - val_loss: 581.9583\nEpoch 56/200\n90/90 [==============================] - 16s 179ms/step - loss: 539.5317 - val_loss: 1125.1407\nEpoch 57/200\n90/90 [==============================] - 16s 181ms/step - loss: 531.5567 - val_loss: 602.9198\nEpoch 58/200\n90/90 [==============================] - 16s 180ms/step - loss: 538.7397 - val_loss: 972.4943\nEpoch 59/200\n90/90 [==============================] - 16s 180ms/step - loss: 505.1974 - val_loss: 494.4193\nEpoch 60/200\n90/90 [==============================] - 17s 187ms/step - loss: 489.0658 - val_loss: 709.5696\nEpoch 61/200\n90/90 [==============================] - 16s 181ms/step - loss: 507.5394 - val_loss: 983.0857\nEpoch 62/200\n90/90 [==============================] - 16s 180ms/step - loss: 459.8011 - val_loss: 736.8964\nEpoch 63/200\n90/90 [==============================] - 16s 181ms/step - loss: 458.5378 - val_loss: 450.0585\nEpoch 64/200\n90/90 [==============================] - 16s 180ms/step - loss: 480.0959 - val_loss: 518.9521\nEpoch 65/200\n90/90 [==============================] - 16s 181ms/step - loss: 479.5205 - val_loss: 457.1074\nEpoch 66/200\n90/90 [==============================] - 16s 180ms/step - loss: 457.6949 - val_loss: 778.0184\nEpoch 67/200\n90/90 [==============================] - 16s 180ms/step - loss: 460.6190 - val_loss: 565.5450\nEpoch 68/200\n90/90 [==============================] - 17s 186ms/step - loss: 398.9080 - val_loss: 473.9186\nEpoch 69/200\n90/90 [==============================] - 17s 187ms/step - loss: 381.4929 - val_loss: 855.6331\nEpoch 70/200\n90/90 [==============================] - 16s 179ms/step - loss: 391.4101 - val_loss: 714.1472\nEpoch 71/200\n90/90 [==============================] - 16s 181ms/step - loss: 400.1362 - val_loss: 605.0884\nEpoch 72/200\n90/90 [==============================] - 16s 180ms/step - loss: 392.7304 - val_loss: 542.4780\nEpoch 73/200\n90/90 [==============================] - 16s 181ms/step - loss: 390.0606 - val_loss: 812.7498\nEpoch 74/200\n90/90 [==============================] - 16s 180ms/step - loss: 390.1771 - val_loss: 655.1603\nEpoch 75/200\n90/90 [==============================] - 16s 180ms/step - loss: 337.2204 - val_loss: 506.3542\nEpoch 76/200\n90/90 [==============================] - 16s 180ms/step - loss: 331.4240 - val_loss: 613.6947\nEpoch 77/200\n90/90 [==============================] - 16s 180ms/step - loss: 337.6184 - val_loss: 511.5260\nEpoch 78/200\n90/90 [==============================] - 16s 179ms/step - loss: 349.2774 - val_loss: 1156.0941\nEpoch 79/200\n90/90 [==============================] - 16s 180ms/step - loss: 362.1318 - val_loss: 479.5452\nEpoch 80/200\n90/90 [==============================] - 16s 179ms/step - loss: 331.8856 - val_loss: 545.7788\nEpoch 81/200\n90/90 [==============================] - 16s 180ms/step - loss: 298.3083 - val_loss: 537.4138\nEpoch 82/200\n90/90 [==============================] - 16s 180ms/step - loss: 295.6551 - val_loss: 676.6866\nEpoch 83/200\n90/90 [==============================] - 16s 180ms/step - loss: 292.6752 - val_loss: 654.6829\nEpoch 84/200\n90/90 [==============================] - 17s 187ms/step - loss: 288.0772 - val_loss: 318.3816\nEpoch 85/200\n90/90 [==============================] - 17s 186ms/step - loss: 276.2929 - val_loss: 549.8793\nEpoch 86/200\n90/90 [==============================] - 16s 180ms/step - loss: 251.4386 - val_loss: 349.0860\nEpoch 87/200\n90/90 [==============================] - 16s 180ms/step - loss: 247.4599 - val_loss: 542.0406\nEpoch 88/200\n90/90 [==============================] - 16s 180ms/step - loss: 243.8957 - val_loss: 365.9769\nEpoch 89/200\n90/90 [==============================] - 16s 180ms/step - loss: 235.4059 - val_loss: 423.5859\nEpoch 90/200\n90/90 [==============================] - 16s 180ms/step - loss: 204.3761 - val_loss: 362.3901\nEpoch 91/200\n90/90 [==============================] - 16s 180ms/step - loss: 211.2585 - val_loss: 380.3336\nEpoch 92/200\n90/90 [==============================] - 16s 181ms/step - loss: 232.3842 - val_loss: 507.1102\nEpoch 93/200\n90/90 [==============================] - 17s 187ms/step - loss: 221.8651 - val_loss: 415.8562\nEpoch 94/200\n90/90 [==============================] - 16s 180ms/step - loss: 214.4980 - val_loss: 432.2374\nEpoch 95/200\n90/90 [==============================] - 16s 179ms/step - loss: 202.0873 - val_loss: 290.3844\nEpoch 96/200\n90/90 [==============================] - 17s 187ms/step - loss: 203.3581 - val_loss: 1286.5942\nEpoch 97/200\n90/90 [==============================] - 16s 180ms/step - loss: 199.1072 - val_loss: 464.7760\nEpoch 98/200\n90/90 [==============================] - 16s 181ms/step - loss: 216.4481 - val_loss: 341.9641\nEpoch 99/200\n90/90 [==============================] - 16s 180ms/step - loss: 211.7856 - val_loss: 392.6621\nEpoch 100/200\n90/90 [==============================] - 16s 180ms/step - loss: 191.3830 - val_loss: 394.2183\nEpoch 101/200\n90/90 [==============================] - 17s 187ms/step - loss: 168.4132 - val_loss: 420.6689\nEpoch 102/200\n90/90 [==============================] - 17s 188ms/step - loss: 182.0894 - val_loss: 387.7569\nEpoch 103/200\n90/90 [==============================] - 17s 188ms/step - loss: 158.8219 - val_loss: 390.2121\nEpoch 104/200\n90/90 [==============================] - 17s 188ms/step - loss: 176.9705 - val_loss: 283.9123\nEpoch 105/200\n90/90 [==============================] - 16s 180ms/step - loss: 160.4236 - val_loss: 356.6598\nEpoch 106/200\n90/90 [==============================] - 16s 181ms/step - loss: 163.6547 - val_loss: 590.1825\nEpoch 107/200\n90/90 [==============================] - 16s 180ms/step - loss: 155.6712 - val_loss: 440.8192\nEpoch 108/200\n90/90 [==============================] - 16s 181ms/step - loss: 153.2806 - val_loss: 303.1131\nEpoch 109/200\n90/90 [==============================] - 17s 188ms/step - loss: 166.9353 - val_loss: 355.5641\nEpoch 110/200\n90/90 [==============================] - 16s 180ms/step - loss: 147.0119 - val_loss: 383.9651\nEpoch 111/200\n90/90 [==============================] - 16s 181ms/step - loss: 119.5503 - val_loss: 357.1255\nEpoch 112/200\n90/90 [==============================] - 16s 180ms/step - loss: 133.2131 - val_loss: 360.5542\nEpoch 113/200\n90/90 [==============================] - 17s 188ms/step - loss: 134.9170 - val_loss: 304.9419\nEpoch 114/200\n90/90 [==============================] - 16s 180ms/step - loss: 131.0235 - val_loss: 332.3635\nEpoch 115/200\n90/90 [==============================] - 16s 181ms/step - loss: 128.2259 - val_loss: 360.6230\nEpoch 116/200\n90/90 [==============================] - 16s 180ms/step - loss: 127.2207 - val_loss: 339.4987\nEpoch 117/200\n90/90 [==============================] - 17s 188ms/step - loss: 133.4615 - val_loss: 283.0089\nEpoch 118/200\n90/90 [==============================] - 16s 180ms/step - loss: 147.6699 - val_loss: 286.2336\nEpoch 119/200\n90/90 [==============================] - 17s 188ms/step - loss: 131.0462 - val_loss: 331.1434\nEpoch 120/200\n90/90 [==============================] - 16s 180ms/step - loss: 105.0344 - val_loss: 276.7695\nEpoch 121/200\n90/90 [==============================] - 16s 181ms/step - loss: 122.6631 - val_loss: 316.3907\nEpoch 122/200\n90/90 [==============================] - 16s 180ms/step - loss: 109.8978 - val_loss: 413.7595\nEpoch 123/200\n90/90 [==============================] - 16s 180ms/step - loss: 109.4091 - val_loss: 310.4245\nEpoch 124/200\n90/90 [==============================] - 16s 180ms/step - loss: 101.4194 - val_loss: 268.1810\nEpoch 125/200\n90/90 [==============================] - 16s 181ms/step - loss: 97.8185 - val_loss: 297.0119\nEpoch 126/200\n90/90 [==============================] - 16s 180ms/step - loss: 103.2613 - val_loss: 258.5624\nEpoch 127/200\n90/90 [==============================] - 16s 180ms/step - loss: 94.8030 - val_loss: 253.3535\nEpoch 128/200\n90/90 [==============================] - 17s 187ms/step - loss: 88.7911 - val_loss: 253.8724\nEpoch 129/200\n90/90 [==============================] - 16s 180ms/step - loss: 90.8134 - val_loss: 311.9278\nEpoch 130/200\n90/90 [==============================] - 16s 180ms/step - loss: 88.9405 - val_loss: 295.8576\nEpoch 131/200\n90/90 [==============================] - 16s 180ms/step - loss: 83.8660 - val_loss: 362.1376\nEpoch 132/200\n90/90 [==============================] - 16s 179ms/step - loss: 80.0062 - val_loss: 259.5291\nEpoch 133/200\n90/90 [==============================] - 16s 180ms/step - loss: 77.5311 - val_loss: 314.7909\nEpoch 134/200\n90/90 [==============================] - 17s 187ms/step - loss: 91.1686 - val_loss: 351.3515\nEpoch 135/200\n90/90 [==============================] - 16s 180ms/step - loss: 88.2819 - val_loss: 281.6514\nEpoch 136/200\n90/90 [==============================] - 17s 187ms/step - loss: 81.9684 - val_loss: 255.0145\nEpoch 137/200\n90/90 [==============================] - 16s 180ms/step - loss: 73.6723 - val_loss: 262.2305\nEpoch 138/200\n90/90 [==============================] - 16s 181ms/step - loss: 72.8424 - val_loss: 255.8996\nEpoch 139/200\n90/90 [==============================] - 16s 180ms/step - loss: 84.2865 - val_loss: 289.5317\nEpoch 140/200\n90/90 [==============================] - 16s 181ms/step - loss: 81.0053 - val_loss: 304.9510\nEpoch 141/200\n90/90 [==============================] - 16s 179ms/step - loss: 89.2090 - val_loss: 221.7758\nEpoch 142/200\n90/90 [==============================] - 16s 181ms/step - loss: 95.0952 - val_loss: 274.0320\nEpoch 143/200\n90/90 [==============================] - 16s 180ms/step - loss: 83.4200 - val_loss: 357.9689\nEpoch 144/200\n90/90 [==============================] - 17s 188ms/step - loss: 82.9218 - val_loss: 247.6446\nEpoch 145/200\n90/90 [==============================] - 17s 186ms/step - loss: 72.8532 - val_loss: 321.4213\nEpoch 146/200\n90/90 [==============================] - 16s 180ms/step - loss: 72.1328 - val_loss: 295.1065\nEpoch 147/200\n90/90 [==============================] - 17s 187ms/step - loss: 64.0416 - val_loss: 267.9425\nEpoch 148/200\n90/90 [==============================] - 17s 188ms/step - loss: 57.8469 - val_loss: 350.7765\nEpoch 149/200\n90/90 [==============================] - 16s 180ms/step - loss: 59.0655 - val_loss: 248.8335\nEpoch 150/200\n90/90 [==============================] - 16s 180ms/step - loss: 62.1825 - val_loss: 247.3299\nEpoch 151/200\n90/90 [==============================] - 16s 180ms/step - loss: 60.9629 - val_loss: 277.8426\nEpoch 152/200\n90/90 [==============================] - 16s 180ms/step - loss: 56.6093 - val_loss: 501.2447\nEpoch 153/200\n90/90 [==============================] - 16s 180ms/step - loss: 69.1417 - val_loss: 259.4812\nEpoch 154/200\n90/90 [==============================] - 16s 181ms/step - loss: 71.4197 - val_loss: 231.1379\nEpoch 155/200\n90/90 [==============================] - 16s 179ms/step - loss: 68.2591 - val_loss: 259.4642\nEpoch 156/200\n90/90 [==============================] - 16s 180ms/step - loss: 63.1616 - val_loss: 245.1733\nEpoch 157/200\n90/90 [==============================] - 16s 179ms/step - loss: 63.4810 - val_loss: 245.5928\nEpoch 158/200\n90/90 [==============================] - 17s 187ms/step - loss: 65.5079 - val_loss: 412.7203\nEpoch 159/200\n90/90 [==============================] - 16s 180ms/step - loss: 75.6655 - val_loss: 245.2749\nEpoch 160/200\n90/90 [==============================] - 17s 187ms/step - loss: 63.5877 - val_loss: 274.6511\nEpoch 161/200\n90/90 [==============================] - 17s 186ms/step - loss: 66.6019 - val_loss: 271.8540\nEpoch 162/200\n90/90 [==============================] - 17s 187ms/step - loss: 65.3853 - val_loss: 299.6048\nEpoch 163/200\n90/90 [==============================] - 16s 180ms/step - loss: 58.2090 - val_loss: 242.8919\nEpoch 164/200\n90/90 [==============================] - 16s 180ms/step - loss: 51.0754 - val_loss: 259.3613\nEpoch 165/200\n90/90 [==============================] - 16s 180ms/step - loss: 52.6320 - val_loss: 243.9056\nEpoch 166/200\n90/90 [==============================] - 17s 186ms/step - loss: 52.7399 - val_loss: 244.4942\nEpoch 167/200\n90/90 [==============================] - 16s 180ms/step - loss: 48.5479 - val_loss: 235.8073\nEpoch 168/200\n90/90 [==============================] - 16s 180ms/step - loss: 50.8345 - val_loss: 255.4315\nEpoch 169/200\n90/90 [==============================] - 16s 181ms/step - loss: 45.4594 - val_loss: 241.6214\nEpoch 170/200\n90/90 [==============================] - 16s 179ms/step - loss: 48.1436 - val_loss: 227.4236\nEpoch 171/200\n90/90 [==============================] - 16s 180ms/step - loss: 47.5112 - val_loss: 280.1111\nEpoch 172/200\n90/90 [==============================] - 16s 180ms/step - loss: 45.1465 - val_loss: 235.2983\nEpoch 173/200\n90/90 [==============================] - 16s 180ms/step - loss: 40.2362 - val_loss: 236.3523\nEpoch 174/200\n90/90 [==============================] - 17s 186ms/step - loss: 45.5176 - val_loss: 220.9712\nEpoch 175/200\n90/90 [==============================] - 16s 180ms/step - loss: 46.3745 - val_loss: 226.5094\nEpoch 176/200\n90/90 [==============================] - 16s 180ms/step - loss: 46.0196 - val_loss: 220.8021\nEpoch 177/200\n90/90 [==============================] - 16s 180ms/step - loss: 47.5103 - val_loss: 237.6790\nEpoch 178/200\n90/90 [==============================] - 16s 180ms/step - loss: 47.1981 - val_loss: 239.1667\nEpoch 179/200\n90/90 [==============================] - 16s 180ms/step - loss: 45.2758 - val_loss: 237.0674\nEpoch 180/200\n90/90 [==============================] - 16s 180ms/step - loss: 46.3885 - val_loss: 242.1705\nEpoch 181/200\n90/90 [==============================] - 17s 187ms/step - loss: 45.8475 - val_loss: 278.4504\nEpoch 182/200\n90/90 [==============================] - 17s 186ms/step - loss: 44.3113 - val_loss: 220.9956\nEpoch 183/200\n90/90 [==============================] - 16s 180ms/step - loss: 43.6420 - val_loss: 216.6718\nEpoch 184/200\n90/90 [==============================] - 17s 186ms/step - loss: 45.6674 - val_loss: 228.8470\nEpoch 185/200\n90/90 [==============================] - 17s 187ms/step - loss: 42.2992 - val_loss: 254.3271\nEpoch 186/200\n90/90 [==============================] - 16s 179ms/step - loss: 45.2557 - val_loss: 231.9736\nEpoch 187/200\n90/90 [==============================] - 16s 180ms/step - loss: 42.8413 - val_loss: 273.0980\nEpoch 188/200\n90/90 [==============================] - 16s 180ms/step - loss: 40.4265 - val_loss: 249.0600\nEpoch 189/200\n90/90 [==============================] - 16s 180ms/step - loss: 39.3892 - val_loss: 246.6998\nEpoch 190/200\n90/90 [==============================] - 16s 180ms/step - loss: 43.2205 - val_loss: 209.3084\nEpoch 191/200\n90/90 [==============================] - 16s 179ms/step - loss: 45.1643 - val_loss: 224.8557\nEpoch 192/200\n90/90 [==============================] - 16s 180ms/step - loss: 41.7662 - val_loss: 211.6070\nEpoch 193/200\n90/90 [==============================] - 16s 179ms/step - loss: 40.3913 - val_loss: 277.1373\nEpoch 194/200\n90/90 [==============================] - 17s 187ms/step - loss: 41.9668 - val_loss: 226.9853\nEpoch 195/200\n90/90 [==============================] - 16s 180ms/step - loss: 50.0298 - val_loss: 241.3038\nEpoch 196/200\n90/90 [==============================] - 16s 180ms/step - loss: 52.1063 - val_loss: 386.5759\nEpoch 197/200\n90/90 [==============================] - 16s 179ms/step - loss: 46.3284 - val_loss: 311.6454\nEpoch 198/200\n90/90 [==============================] - 16s 180ms/step - loss: 47.3466 - val_loss: 220.3326\nEpoch 199/200\n90/90 [==============================] - 16s 180ms/step - loss: 41.2791 - val_loss: 253.7620\nEpoch 200/200\n90/90 [==============================] - 16s 180ms/step - loss: 34.7308 - val_loss: 241.8772\nFinal Training Loss: 34.7308\nFinal Validation Loss: 241.8772\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow import keras\n\n# Load the pre-trained model\nmodel = keras.models.load_model('/kaggle/working/icu_machine_detection_model.h5')  # Adjust the path if needed\n\n# Load the sample submission file\nsample_submission = pd.read_csv('/kaggle/input/iitgai-ovha-23/sample_submission.csv')\n\n# Assuming test images are in the '/kaggle/input/iitgai-ovha-23/test_images/' folder\ntest_image_paths = sample_submission['image_name'].apply(lambda x: f'/kaggle/input/iitgai-ovha-23/test_images/{x}')\n\n# Function to load and preprocess test images\ndef load_and_preprocess_test_image(image_path):\n    img = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n    img = keras.preprocessing.image.img_to_array(img)\n    img = keras.applications.resnet50.preprocess_input(img)\n    return img\n\ntest_images = np.array([load_and_preprocess_test_image(path) for path in test_image_paths])\n\n# Predict coordinates for test images\npredicted_coordinates = model.predict(test_images)\n\n# Create a DataFrame with image names and predicted coordinates\nsubmission_df = pd.DataFrame({\n    'image_name': sample_submission['image_name'],\n    'points': [f\"[{coord[0]:.1f}, {coord[1]:.1f}, {coord[2]:.1f}, {coord[3]:.1f}, {coord[4]:.1f}, {coord[5]:.1f}, {coord[6]:.1f}, {coord[7]:.1f}]\" for coord in predicted_coordinates]\n})\n\n# Save the submission DataFrame as a CSV file\nsubmission_df.to_csv('/kaggle/working/icu_machine_detection_submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T17:59:10.669648Z","iopub.execute_input":"2023-10-15T17:59:10.669975Z","iopub.status.idle":"2023-10-15T17:59:19.351901Z","shell.execute_reply.started":"2023-10-15T17:59:10.669949Z","shell.execute_reply":"2023-10-15T17:59:19.350921Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"8/8 [==============================] - 2s 123ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Load labels\ndf = pd.read_csv('/kaggle/input/iitgai-ovha-23/train_labels.csv')  \n\n# Assuming images are in the '/kaggle/input/iitgai-ovha-23/images/' folder\nimage_paths = df['image_name'].apply(lambda x: f'/kaggle/input/iitgai-ovha-23/images/{x}')\n\n# Function to load and preprocess images\ndef load_and_preprocess_image(image_path):\n    img = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n    img = keras.preprocessing.image.img_to_array(img)\n    img = keras.applications.resnet50.preprocess_input(img)\n    return img\n\nimages = np.array([load_and_preprocess_image(path) for path in image_paths])\n\n# Function to parse points from the 'points' column\ndef parse_points(points_str):\n    try:\n        # If points are already in list format as strings, eval() will convert them to a list\n        if isinstance(points_str, str):\n            return eval(points_str)\n        else:\n            return points_str\n    except Exception as e:\n        print(f\"Error parsing points: {e}, points_str: {points_str}\")\n        return None\n\n# Apply the parse_points function and remove problematic points\nlabels = df['points'].apply(parse_points)\nlabels = labels.dropna()\n\n# Convert labels to numpy array\nlabels = np.array(labels.tolist())\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n\n# Apply data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Initialize an empty list to store augmented images and labels\naugmented_images = []\naugmented_labels = []\n\n# Apply data augmentation to each image and its corresponding label\nfor image, label in zip(X_train, y_train):\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    augmented_images.extend(datagen.flow(image).next())\n    augmented_labels.extend([label] * len(datagen.flow(image).next()))\n\n# Convert the lists of augmented images and labels back to numpy arrays\naugmented_images = np.array(augmented_images)\naugmented_labels = np.array(augmented_labels)\n\n# Combine original and augmented data\nX_combined = np.vstack((X_train, augmented_images))\ny_combined = np.vstack((y_train, augmented_labels))  # Assuming labels are 2D\n\n# Define a function to adjust learning rate after 180 epochs\ndef lr_scheduler(epoch):\n    if epoch < 180:\n        return 0.0001  # Keep learning rate as 0.0001 for the first 180 epochs\n    else:\n        return 0.00001  # Change learning rate to 0.00001 after 180 epochs\n\n# Define callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nlr_schedule = LearningRateScheduler(lr_scheduler)\n\n# Load pre-trained ResNet model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add L2 regularization to the dense layer\nmodel = keras.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(8, kernel_regularizer=l2(0.00001))  # Add L2 regularization with alpha=0.00001\n])\n\n# Train the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')\nhistory = model.fit(X_combined, y_combined, validation_data=(X_val, y_val), epochs=200, batch_size=32, callbacks=[early_stopping, lr_schedule])\n\n# Save the model\nmodel.save('/kaggle/working/icu_machine_detection_model.h5') \n\n# Print the final cost function (loss) of train and validation set\ntrain_loss = history.history['loss'][-1]\nval_loss = history.history['val_loss'][-1]\nprint(f'Final Training Loss: {train_loss:.4f}')\nprint(f'Final Validation Loss: {val_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T18:08:05.066058Z","iopub.execute_input":"2023-10-15T18:08:05.066741Z","iopub.status.idle":"2023-10-15T18:29:51.685069Z","shell.execute_reply.started":"2023-10-15T18:08:05.066694Z","shell.execute_reply":"2023-10-15T18:29:51.684064Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 3s 0us/step\nEpoch 1/200\n90/90 [==============================] - 63s 206ms/step - loss: 289128.6562 - val_loss: 123782.2422 - lr: 1.0000e-04\nEpoch 2/200\n90/90 [==============================] - 17s 185ms/step - loss: 262298.7812 - val_loss: 183934.0156 - lr: 1.0000e-04\nEpoch 3/200\n90/90 [==============================] - 17s 186ms/step - loss: 241923.8594 - val_loss: 230168.5156 - lr: 1.0000e-04\nEpoch 4/200\n90/90 [==============================] - 16s 178ms/step - loss: 222635.3125 - val_loss: 194361.2656 - lr: 1.0000e-04\nEpoch 5/200\n90/90 [==============================] - 16s 179ms/step - loss: 204733.9375 - val_loss: 195221.1094 - lr: 1.0000e-04\nEpoch 6/200\n90/90 [==============================] - 16s 178ms/step - loss: 187974.2031 - val_loss: 163754.0156 - lr: 1.0000e-04\nEpoch 7/200\n90/90 [==============================] - 16s 178ms/step - loss: 171555.1562 - val_loss: 141836.8281 - lr: 1.0000e-04\nEpoch 8/200\n90/90 [==============================] - 16s 178ms/step - loss: 155855.3750 - val_loss: 179439.3594 - lr: 1.0000e-04\nEpoch 9/200\n90/90 [==============================] - 17s 185ms/step - loss: 140534.0312 - val_loss: 141120.7031 - lr: 1.0000e-04\nEpoch 10/200\n90/90 [==============================] - 16s 178ms/step - loss: 125390.7031 - val_loss: 150573.1719 - lr: 1.0000e-04\nEpoch 11/200\n90/90 [==============================] - 16s 180ms/step - loss: 112309.0859 - val_loss: 73226.3828 - lr: 1.0000e-04\nEpoch 12/200\n90/90 [==============================] - 16s 178ms/step - loss: 100096.7422 - val_loss: 96984.7812 - lr: 1.0000e-04\nEpoch 13/200\n90/90 [==============================] - 16s 178ms/step - loss: 88447.3828 - val_loss: 79188.6797 - lr: 1.0000e-04\nEpoch 14/200\n90/90 [==============================] - 16s 178ms/step - loss: 78468.4141 - val_loss: 75023.4766 - lr: 1.0000e-04\nEpoch 15/200\n90/90 [==============================] - 16s 179ms/step - loss: 69079.1797 - val_loss: 86309.5859 - lr: 1.0000e-04\nEpoch 16/200\n90/90 [==============================] - 16s 179ms/step - loss: 60547.6016 - val_loss: 49660.2656 - lr: 1.0000e-04\nEpoch 17/200\n90/90 [==============================] - 16s 180ms/step - loss: 53225.8398 - val_loss: 39324.5352 - lr: 1.0000e-04\nEpoch 18/200\n90/90 [==============================] - 16s 179ms/step - loss: 45715.1289 - val_loss: 37830.1992 - lr: 1.0000e-04\nEpoch 19/200\n90/90 [==============================] - 16s 180ms/step - loss: 39419.3008 - val_loss: 33022.4453 - lr: 1.0000e-04\nEpoch 20/200\n90/90 [==============================] - 16s 179ms/step - loss: 34287.0625 - val_loss: 30861.9414 - lr: 1.0000e-04\nEpoch 21/200\n90/90 [==============================] - 16s 180ms/step - loss: 29464.4590 - val_loss: 23576.0215 - lr: 1.0000e-04\nEpoch 22/200\n90/90 [==============================] - 16s 179ms/step - loss: 25041.3887 - val_loss: 22130.4023 - lr: 1.0000e-04\nEpoch 23/200\n90/90 [==============================] - 16s 178ms/step - loss: 21432.4453 - val_loss: 25420.2637 - lr: 1.0000e-04\nEpoch 24/200\n90/90 [==============================] - 16s 179ms/step - loss: 18100.9355 - val_loss: 16309.4775 - lr: 1.0000e-04\nEpoch 25/200\n90/90 [==============================] - 16s 180ms/step - loss: 15408.7148 - val_loss: 12211.0195 - lr: 1.0000e-04\nEpoch 26/200\n90/90 [==============================] - 16s 178ms/step - loss: 13301.2373 - val_loss: 12812.3389 - lr: 1.0000e-04\nEpoch 27/200\n90/90 [==============================] - 16s 179ms/step - loss: 11385.5791 - val_loss: 16526.8633 - lr: 1.0000e-04\nEpoch 28/200\n90/90 [==============================] - 16s 179ms/step - loss: 9552.9932 - val_loss: 9034.6523 - lr: 1.0000e-04\nEpoch 29/200\n90/90 [==============================] - 16s 180ms/step - loss: 8108.5942 - val_loss: 8714.2246 - lr: 1.0000e-04\nEpoch 30/200\n90/90 [==============================] - 16s 179ms/step - loss: 6832.4951 - val_loss: 4744.8350 - lr: 1.0000e-04\nEpoch 31/200\n90/90 [==============================] - 16s 178ms/step - loss: 5781.0537 - val_loss: 6995.2583 - lr: 1.0000e-04\nEpoch 32/200\n90/90 [==============================] - 16s 178ms/step - loss: 4857.7651 - val_loss: 8096.3999 - lr: 1.0000e-04\nEpoch 33/200\n90/90 [==============================] - 16s 179ms/step - loss: 3898.2263 - val_loss: 3156.2954 - lr: 1.0000e-04\nEpoch 34/200\n90/90 [==============================] - 17s 185ms/step - loss: 3054.2683 - val_loss: 6089.2930 - lr: 1.0000e-04\nEpoch 35/200\n90/90 [==============================] - 16s 178ms/step - loss: 2549.3838 - val_loss: 4805.2563 - lr: 1.0000e-04\nEpoch 36/200\n90/90 [==============================] - 16s 178ms/step - loss: 1846.9054 - val_loss: 4161.2065 - lr: 1.0000e-04\nEpoch 37/200\n90/90 [==============================] - 16s 180ms/step - loss: 1512.4375 - val_loss: 1960.4241 - lr: 1.0000e-04\nEpoch 38/200\n90/90 [==============================] - 16s 178ms/step - loss: 1252.1898 - val_loss: 3120.8872 - lr: 1.0000e-04\nEpoch 39/200\n90/90 [==============================] - 17s 187ms/step - loss: 1028.5916 - val_loss: 1409.2490 - lr: 1.0000e-04\nEpoch 40/200\n90/90 [==============================] - 16s 179ms/step - loss: 944.4102 - val_loss: 1150.7943 - lr: 1.0000e-04\nEpoch 41/200\n90/90 [==============================] - 16s 178ms/step - loss: 843.3109 - val_loss: 1994.6239 - lr: 1.0000e-04\nEpoch 42/200\n90/90 [==============================] - 16s 178ms/step - loss: 753.3813 - val_loss: 1653.5299 - lr: 1.0000e-04\nEpoch 43/200\n90/90 [==============================] - 16s 180ms/step - loss: 696.4479 - val_loss: 710.4496 - lr: 1.0000e-04\nEpoch 44/200\n90/90 [==============================] - 16s 177ms/step - loss: 723.6976 - val_loss: 1044.9264 - lr: 1.0000e-04\nEpoch 45/200\n90/90 [==============================] - 16s 179ms/step - loss: 615.5144 - val_loss: 648.5255 - lr: 1.0000e-04\nEpoch 46/200\n90/90 [==============================] - 16s 178ms/step - loss: 639.4518 - val_loss: 826.0477 - lr: 1.0000e-04\nEpoch 47/200\n90/90 [==============================] - 16s 178ms/step - loss: 687.0430 - val_loss: 11007.8418 - lr: 1.0000e-04\nEpoch 48/200\n90/90 [==============================] - 16s 178ms/step - loss: 651.8588 - val_loss: 1440.0703 - lr: 1.0000e-04\nEpoch 49/200\n90/90 [==============================] - 16s 178ms/step - loss: 586.5632 - val_loss: 1059.7799 - lr: 1.0000e-04\nEpoch 50/200\n90/90 [==============================] - 16s 178ms/step - loss: 566.0212 - val_loss: 1062.9934 - lr: 1.0000e-04\nEpoch 51/200\n90/90 [==============================] - 16s 178ms/step - loss: 538.0380 - val_loss: 792.7874 - lr: 1.0000e-04\nEpoch 52/200\n90/90 [==============================] - 16s 178ms/step - loss: 487.7537 - val_loss: 1147.7410 - lr: 1.0000e-04\nEpoch 53/200\n90/90 [==============================] - 16s 179ms/step - loss: 525.3732 - val_loss: 2520.7231 - lr: 1.0000e-04\nEpoch 54/200\n90/90 [==============================] - 16s 178ms/step - loss: 481.9544 - val_loss: 1286.1437 - lr: 1.0000e-04\nEpoch 55/200\n90/90 [==============================] - 16s 180ms/step - loss: 463.0171 - val_loss: 578.7362 - lr: 1.0000e-04\nEpoch 56/200\n90/90 [==============================] - 16s 178ms/step - loss: 495.0186 - val_loss: 790.6476 - lr: 1.0000e-04\nEpoch 57/200\n90/90 [==============================] - 16s 178ms/step - loss: 491.0750 - val_loss: 825.1553 - lr: 1.0000e-04\nEpoch 58/200\n90/90 [==============================] - 16s 178ms/step - loss: 457.7771 - val_loss: 719.3593 - lr: 1.0000e-04\nEpoch 59/200\n90/90 [==============================] - 16s 179ms/step - loss: 439.8177 - val_loss: 664.3992 - lr: 1.0000e-04\nEpoch 60/200\n90/90 [==============================] - 16s 179ms/step - loss: 462.4979 - val_loss: 463.2276 - lr: 1.0000e-04\nEpoch 61/200\n90/90 [==============================] - 16s 179ms/step - loss: 444.0061 - val_loss: 593.1585 - lr: 1.0000e-04\nEpoch 62/200\n90/90 [==============================] - 16s 178ms/step - loss: 456.1841 - val_loss: 579.8110 - lr: 1.0000e-04\nEpoch 63/200\n90/90 [==============================] - 16s 178ms/step - loss: 418.9489 - val_loss: 642.2742 - lr: 1.0000e-04\nEpoch 64/200\n90/90 [==============================] - 16s 178ms/step - loss: 425.8115 - val_loss: 2300.0332 - lr: 1.0000e-04\nEpoch 65/200\n90/90 [==============================] - 16s 178ms/step - loss: 456.8662 - val_loss: 1323.2812 - lr: 1.0000e-04\nEpoch 66/200\n90/90 [==============================] - 16s 178ms/step - loss: 412.8177 - val_loss: 572.2070 - lr: 1.0000e-04\nEpoch 67/200\n90/90 [==============================] - 16s 178ms/step - loss: 404.1960 - val_loss: 467.8405 - lr: 1.0000e-04\nEpoch 68/200\n90/90 [==============================] - 16s 178ms/step - loss: 368.4853 - val_loss: 1817.3076 - lr: 1.0000e-04\nEpoch 69/200\n90/90 [==============================] - 16s 179ms/step - loss: 365.4056 - val_loss: 961.5391 - lr: 1.0000e-04\nEpoch 70/200\n90/90 [==============================] - 16s 180ms/step - loss: 345.8746 - val_loss: 524.8574 - lr: 1.0000e-04\nFinal Training Loss: 345.8746\nFinal Validation Loss: 524.8574\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Load labels\ndf = pd.read_csv('/kaggle/input/iitgai-ovha-23/train_labels.csv')  \n\n# Assuming images are in the '/kaggle/input/iitgai-ovha-23/images/' folder\nimage_paths = df['image_name'].apply(lambda x: f'/kaggle/input/iitgai-ovha-23/images/{x}')\n\n# Function to load and preprocess images\ndef load_and_preprocess_image(image_path):\n    img = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n    img = keras.preprocessing.image.img_to_array(img)\n    img = keras.applications.resnet50.preprocess_input(img)\n    return img\n\nimages = np.array([load_and_preprocess_image(path) for path in image_paths])\n\n# Function to parse points from the 'points' column\ndef parse_points(points_str):\n    try:\n        # If points are already in list format as strings, eval() will convert them to a list\n        if isinstance(points_str, str):\n            return eval(points_str)\n        else:\n            return points_str\n    except Exception as e:\n        print(f\"Error parsing points: {e}, points_str: {points_str}\")\n        return None\n\n# Apply the parse_points function and remove problematic points\nlabels = df['points'].apply(parse_points)\nlabels = labels.dropna()\n\n# Convert labels to numpy array\nlabels = np.array(labels.tolist())\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n\n# Load pre-trained ResNet model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add L2 regularization to the dense layer\nmodel = keras.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(8, kernel_regularizer=l2(0.00001))  # Add L2 regularization with alpha=0.00001\n])\n\n# Load the previously saved model\nmodel.load_weights('/kaggle/working/icu_machine_detection_model.h5')\n\n# Define a function to adjust learning rate after 180 epochs\ndef lr_scheduler(epoch):\n    if epoch < 180:\n        return 0.0001  # Keep learning rate as 0.0001 for the first 180 epochs\n    else:\n        return 0.00001  # Change learning rate to 0.00001 after 180 epochs\n\n# Define callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nlr_schedule = LearningRateScheduler(lr_scheduler)\n\n# Train the model starting from epoch 70\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, initial_epoch=70, batch_size=32, callbacks=[early_stopping, lr_schedule])\n\n# Save the model\nmodel.save('/kaggle/working/icu_machine_detection_model.h5') \n\n# Print the final cost function (loss) of train and validation set\ntrain_loss = history.history['loss'][-1]\nval_loss = history.history['val_loss'][-1]\nprint(f'Final Training Loss: {train_loss:.4f}')\nprint(f'Final Validation Loss: {val_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-15T18:34:11.175529Z","iopub.execute_input":"2023-10-15T18:34:11.175884Z","iopub.status.idle":"2023-10-15T18:39:12.235480Z","shell.execute_reply.started":"2023-10-15T18:34:11.175857Z","shell.execute_reply":"2023-10-15T18:39:12.234360Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Epoch 71/200\n45/45 [==============================] - 45s 223ms/step - loss: 539.9044 - val_loss: 1373.1417 - lr: 1.0000e-04\nEpoch 72/200\n45/45 [==============================] - 8s 189ms/step - loss: 404.1269 - val_loss: 860.9225 - lr: 1.0000e-04\nEpoch 73/200\n45/45 [==============================] - 8s 187ms/step - loss: 348.7886 - val_loss: 1219.3771 - lr: 1.0000e-04\nEpoch 74/200\n45/45 [==============================] - 8s 187ms/step - loss: 406.4791 - val_loss: 2000.8280 - lr: 1.0000e-04\nEpoch 75/200\n45/45 [==============================] - 8s 186ms/step - loss: 363.2711 - val_loss: 1429.9757 - lr: 1.0000e-04\nEpoch 76/200\n45/45 [==============================] - 8s 186ms/step - loss: 335.4020 - val_loss: 2745.1133 - lr: 1.0000e-04\nEpoch 77/200\n45/45 [==============================] - 9s 200ms/step - loss: 284.2615 - val_loss: 1813.9094 - lr: 1.0000e-04\nEpoch 78/200\n45/45 [==============================] - 8s 186ms/step - loss: 302.0045 - val_loss: 911.8030 - lr: 1.0000e-04\nEpoch 79/200\n45/45 [==============================] - 8s 189ms/step - loss: 250.1306 - val_loss: 547.6734 - lr: 1.0000e-04\nEpoch 80/200\n45/45 [==============================] - 8s 186ms/step - loss: 279.6772 - val_loss: 686.0862 - lr: 1.0000e-04\nEpoch 81/200\n45/45 [==============================] - 8s 188ms/step - loss: 205.7353 - val_loss: 1146.1329 - lr: 1.0000e-04\nEpoch 82/200\n45/45 [==============================] - 9s 189ms/step - loss: 255.6643 - val_loss: 256.2863 - lr: 1.0000e-04\nEpoch 83/200\n45/45 [==============================] - 8s 186ms/step - loss: 274.3097 - val_loss: 1111.9382 - lr: 1.0000e-04\nEpoch 84/200\n45/45 [==============================] - 8s 186ms/step - loss: 212.5970 - val_loss: 420.3817 - lr: 1.0000e-04\nEpoch 85/200\n45/45 [==============================] - 9s 201ms/step - loss: 226.2316 - val_loss: 761.1213 - lr: 1.0000e-04\nEpoch 86/200\n45/45 [==============================] - 8s 186ms/step - loss: 210.3049 - val_loss: 501.6086 - lr: 1.0000e-04\nEpoch 87/200\n45/45 [==============================] - 8s 186ms/step - loss: 195.7226 - val_loss: 739.4735 - lr: 1.0000e-04\nEpoch 88/200\n45/45 [==============================] - 8s 186ms/step - loss: 177.0256 - val_loss: 605.3876 - lr: 1.0000e-04\nEpoch 89/200\n45/45 [==============================] - 9s 201ms/step - loss: 182.5395 - val_loss: 824.1978 - lr: 1.0000e-04\nEpoch 90/200\n45/45 [==============================] - 8s 186ms/step - loss: 142.5584 - val_loss: 387.1618 - lr: 1.0000e-04\nEpoch 91/200\n45/45 [==============================] - 8s 186ms/step - loss: 139.9736 - val_loss: 295.0775 - lr: 1.0000e-04\nEpoch 92/200\n45/45 [==============================] - 9s 205ms/step - loss: 151.4595 - val_loss: 282.4271 - lr: 1.0000e-04\nFinal Training Loss: 151.4595\nFinal Validation Loss: 282.4271\n","output_type":"stream"}]},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# from tensorflow import keras\n# from tensorflow.keras import layers\n# from tensorflow.keras.applications import ResNet50\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n# from tensorflow.keras.regularizers import l2\n# from sklearn.model_selection import train_test_split\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# # Load labels\n# df = pd.read_csv('/kaggle/input/iitgai-ovha-23/train_labels.csv')  \n\n# # Assuming images are in the '/kaggle/input/iitgai-ovha-23/images/' folder\n# image_paths = df['image_name'].apply(lambda x: f'/kaggle/input/iitgai-ovha-23/images/{x}')\n\n# # Function to load and preprocess images\n# def load_and_preprocess_image(image_path):\n#     img = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n#     img = keras.preprocessing.image.img_to_array(img)\n#     img = keras.applications.resnet50.preprocess_input(img)\n#     return img\n\n# images = np.array([load_and_preprocess_image(path) for path in image_paths])\n\n# # Function to parse points from the 'points' column\n# def parse_points(points_str):\n#     try:\n#         # If points are already in list format as strings, eval() will convert them to a list\n#         if isinstance(points_str, str):\n#             return eval(points_str)\n#         else:\n#             return points_str\n#     except Exception as e:\n#         print(f\"Error parsing points: {e}, points_str: {points_str}\")\n#         return None\n\n# # Apply the parse_points function and remove problematic points\n# labels = df['points'].apply(parse_points)\n# labels = labels.dropna()\n\n# # Convert labels to numpy array\n# labels = np.array(labels.tolist())\n\n# # Split data into training and validation sets\n# X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n\n# # Load pre-trained ResNet model\n# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# # Add L2 regularization to the dense layer\n# model = keras.Sequential([\n#     base_model,\n#     layers.GlobalAveragePooling2D(),\n#     layers.Dense(8, kernel_regularizer=l2(0.00001))  # Add L2 regularization with alpha=0.00001\n# ])\n\n# # Load the previously saved model\n# model.load_weights('/kaggle/working/icu_machine_detection_model.h5')\n\n# # Define a function to adjust learning rate after 180 epochs\n# def lr_scheduler(epoch):\n#     if epoch < 180:\n#         return 0.0001  # Keep learning rate as 0.0001 for the first 180 epochs\n#     else:\n#         return 0.00001  # Change learning rate to 0.00001 after 180 epochs\n\n# # Define callbacks\n# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n# lr_schedule = LearningRateScheduler(lr_scheduler)\n\n# # Train the model starting from epoch 92\n# model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')\n# history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, initial_epoch=92, batch_size=32, callbacks=[early_stopping, lr_schedule])\n\n# # Save the model\n# model.save('/kaggle/working/icu_machine_detection_model.h5') \n\n# # Print the final cost function (loss) of train and validation set\n# train_loss = history.history['loss'][-1]\n# val_loss = history.history['val_loss'][-1]\n# print(f'Final Training Loss: {train_loss:.4f}')\n# print(f'Final Validation Loss: {val_loss:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T10:49:05.088468Z","iopub.execute_input":"2024-02-01T10:49:05.089289Z","iopub.status.idle":"2024-02-01T10:49:05.097030Z","shell.execute_reply.started":"2024-02-01T10:49:05.089246Z","shell.execute_reply":"2024-02-01T10:49:05.095961Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}